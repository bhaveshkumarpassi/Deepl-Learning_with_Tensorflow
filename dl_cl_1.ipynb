{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df = pd.DataFrame(X,columns=cancer['feature_names'])\n",
    "cancer_df['target'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15891fa8240>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(cancer_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target                     1.000000\n",
       "smoothness error           0.067016\n",
       "mean fractal dimension     0.012838\n",
       "texture error              0.008303\n",
       "symmetry error             0.006522\n",
       "fractal dimension error   -0.077972\n",
       "concavity error           -0.253730\n",
       "compactness error         -0.292999\n",
       "worst fractal dimension   -0.323872\n",
       "mean symmetry             -0.330499\n",
       "mean smoothness           -0.358560\n",
       "concave points error      -0.408042\n",
       "mean texture              -0.415185\n",
       "worst symmetry            -0.416294\n",
       "worst smoothness          -0.421465\n",
       "worst texture             -0.456903\n",
       "area error                -0.548236\n",
       "perimeter error           -0.556141\n",
       "radius error              -0.567134\n",
       "worst compactness         -0.590998\n",
       "mean compactness          -0.596534\n",
       "worst concavity           -0.659610\n",
       "mean concavity            -0.696360\n",
       "mean area                 -0.708984\n",
       "mean radius               -0.730029\n",
       "worst area                -0.733825\n",
       "mean perimeter            -0.742636\n",
       "worst radius              -0.776454\n",
       "mean concave points       -0.776614\n",
       "worst perimeter           -0.782914\n",
       "worst concave points      -0.793566\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.corr()['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "\n",
    "model.add(Dense(15,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 0s 808us/sample - loss: 0.6655 - val_loss: 0.6428\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.6153 - val_loss: 0.5915\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.5662 - val_loss: 0.5439\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.5189 - val_loss: 0.4933\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.4688 - val_loss: 0.4416\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.4203 - val_loss: 0.3917\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.3736 - val_loss: 0.3458\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.3356 - val_loss: 0.3064\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.3014 - val_loss: 0.2735\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.2759 - val_loss: 0.2502\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.2512 - val_loss: 0.2265\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.2325 - val_loss: 0.2120\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.2172 - val_loss: 0.1964\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.2018 - val_loss: 0.1817\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1906 - val_loss: 0.1727\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1794 - val_loss: 0.1619\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1702 - val_loss: 0.1537\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.1617 - val_loss: 0.1473\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1538 - val_loss: 0.1414\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1477 - val_loss: 0.1346\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1431 - val_loss: 0.1376\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1336 - val_loss: 0.1239\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1281 - val_loss: 0.1243\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1231 - val_loss: 0.1174\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.1171 - val_loss: 0.1153\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1125 - val_loss: 0.1141\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1080 - val_loss: 0.1085\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.1062 - val_loss: 0.1134\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1094 - val_loss: 0.1038\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.1001 - val_loss: 0.1059\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0943 - val_loss: 0.1051\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0898 - val_loss: 0.0996\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0880 - val_loss: 0.1008\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0879 - val_loss: 0.0976\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0849 - val_loss: 0.1001\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0803 - val_loss: 0.0977\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0786 - val_loss: 0.0944\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0761 - val_loss: 0.0972\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0748 - val_loss: 0.0951\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0737 - val_loss: 0.0964\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0741 - val_loss: 0.0954\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0731 - val_loss: 0.0931\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0694 - val_loss: 0.0914\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0680 - val_loss: 0.0947\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0663 - val_loss: 0.0917\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0658 - val_loss: 0.0910\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0645 - val_loss: 0.0945\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0630 - val_loss: 0.0932\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0620 - val_loss: 0.0935\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0610 - val_loss: 0.0939\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0608 - val_loss: 0.0916\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0607 - val_loss: 0.0945\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0595 - val_loss: 0.0917\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0583 - val_loss: 0.0930\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0606 - val_loss: 0.0932\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0626 - val_loss: 0.0926\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0608 - val_loss: 0.0959\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0557 - val_loss: 0.0934\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0563 - val_loss: 0.0931\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0555 - val_loss: 0.0949\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0550 - val_loss: 0.0943\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0551 - val_loss: 0.0949\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0536 - val_loss: 0.0941\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0528 - val_loss: 0.0942\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0529 - val_loss: 0.0925\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0521 - val_loss: 0.0945\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0532 - val_loss: 0.0993\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0519 - val_loss: 0.0973\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0520 - val_loss: 0.0969\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0517 - val_loss: 0.0929\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0511 - val_loss: 0.0955\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0511 - val_loss: 0.0999\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0517 - val_loss: 0.0952\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0489 - val_loss: 0.0986\n",
      "Epoch 75/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0496 - val_loss: 0.0988\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0481 - val_loss: 0.0963\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0486 - val_loss: 0.0944\n",
      "Epoch 78/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0511 - val_loss: 0.0986\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0541 - val_loss: 0.0943\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0467 - val_loss: 0.0994\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0488 - val_loss: 0.0947\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0493 - val_loss: 0.0933\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.048 - 0s 56us/sample - loss: 0.0475 - val_loss: 0.0938\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0465 - val_loss: 0.0999\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0451 - val_loss: 0.0964\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0452 - val_loss: 0.0976\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0496 - val_loss: 0.0941\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0456 - val_loss: 0.0995\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0452 - val_loss: 0.0997\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.039 - 0s 38us/sample - loss: 0.0440 - val_loss: 0.0998\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0445 - val_loss: 0.0995\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0440 - val_loss: 0.0961\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0427 - val_loss: 0.1003\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0419 - val_loss: 0.0948\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0450 - val_loss: 0.1023\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0490 - val_loss: 0.0956\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0443 - val_loss: 0.1010\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0424 - val_loss: 0.0979\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0418 - val_loss: 0.0999\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0422 - val_loss: 0.0998\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0453 - val_loss: 0.0937\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0431 - val_loss: 0.0976\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0415 - val_loss: 0.0973\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0417 - val_loss: 0.0973\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0396 - val_loss: 0.0932\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0411 - val_loss: 0.0962\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0433 - val_loss: 0.1006\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0443 - val_loss: 0.1017\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0397 - val_loss: 0.0985\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0399 - val_loss: 0.1016\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0379 - val_loss: 0.0962\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0408 - val_loss: 0.1053\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0397 - val_loss: 0.0970\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0378 - val_loss: 0.1052\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0378 - val_loss: 0.0987\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0378 - val_loss: 0.0969\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0379 - val_loss: 0.1034\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0382 - val_loss: 0.1001\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0367 - val_loss: 0.1006\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0361 - val_loss: 0.0983\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0376 - val_loss: 0.0984\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0372 - val_loss: 0.1009\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.061 - 0s 56us/sample - loss: 0.0362 - val_loss: 0.0995\n",
      "Epoch 124/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0357 - val_loss: 0.0987\n",
      "Epoch 125/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0352 - val_loss: 0.0985\n",
      "Epoch 126/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0373 - val_loss: 0.1027\n",
      "Epoch 127/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0371 - val_loss: 0.0979\n",
      "Epoch 128/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0352 - val_loss: 0.0990\n",
      "Epoch 129/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0345 - val_loss: 0.0978\n",
      "Epoch 130/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0363 - val_loss: 0.1056\n",
      "Epoch 131/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0348 - val_loss: 0.0964\n",
      "Epoch 132/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0343 - val_loss: 0.1038\n",
      "Epoch 133/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0334 - val_loss: 0.1005\n",
      "Epoch 134/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0331 - val_loss: 0.0972\n",
      "Epoch 135/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0338 - val_loss: 0.1048\n",
      "Epoch 136/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0361 - val_loss: 0.0977\n",
      "Epoch 137/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0337 - val_loss: 0.1035\n",
      "Epoch 138/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0321 - val_loss: 0.0972\n",
      "Epoch 139/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0329 - val_loss: 0.1013\n",
      "Epoch 140/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0317 - val_loss: 0.0978\n",
      "Epoch 141/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0317 - val_loss: 0.0990\n",
      "Epoch 142/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0344 - val_loss: 0.0962\n",
      "Epoch 143/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0382 - val_loss: 0.1070\n",
      "Epoch 144/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0330 - val_loss: 0.0982\n",
      "Epoch 145/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0315 - val_loss: 0.0951\n",
      "Epoch 146/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0307 - val_loss: 0.0975\n",
      "Epoch 147/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0298 - val_loss: 0.0989\n",
      "Epoch 148/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0326 - val_loss: 0.0996\n",
      "Epoch 149/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0327 - val_loss: 0.0945\n",
      "Epoch 150/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0326 - val_loss: 0.1000\n",
      "Epoch 151/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0296 - val_loss: 0.0975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0298 - val_loss: 0.1033\n",
      "Epoch 153/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0296 - val_loss: 0.0959\n",
      "Epoch 154/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0301 - val_loss: 0.0952\n",
      "Epoch 155/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0291 - val_loss: 0.0997\n",
      "Epoch 156/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0294 - val_loss: 0.0953\n",
      "Epoch 157/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0290 - val_loss: 0.1001\n",
      "Epoch 158/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0326 - val_loss: 0.0938\n",
      "Epoch 159/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0332 - val_loss: 0.1106\n",
      "Epoch 160/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.003 - 0s 38us/sample - loss: 0.0274 - val_loss: 0.0942\n",
      "Epoch 161/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.009 - 0s 56us/sample - loss: 0.0322 - val_loss: 0.1090\n",
      "Epoch 162/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0311 - val_loss: 0.0941\n",
      "Epoch 163/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0286 - val_loss: 0.1018\n",
      "Epoch 164/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0269 - val_loss: 0.0930\n",
      "Epoch 165/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0270 - val_loss: 0.0994\n",
      "Epoch 166/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0264 - val_loss: 0.0947\n",
      "Epoch 167/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0270 - val_loss: 0.0944\n",
      "Epoch 168/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0277 - val_loss: 0.0913\n",
      "Epoch 169/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0272 - val_loss: 0.0917\n",
      "Epoch 170/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0253 - val_loss: 0.1024\n",
      "Epoch 171/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0263 - val_loss: 0.0944\n",
      "Epoch 172/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0271 - val_loss: 0.0956\n",
      "Epoch 173/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0282 - val_loss: 0.1053\n",
      "Epoch 174/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0306 - val_loss: 0.0917\n",
      "Epoch 175/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0268 - val_loss: 0.1019\n",
      "Epoch 176/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0259 - val_loss: 0.0946\n",
      "Epoch 177/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0248 - val_loss: 0.0922\n",
      "Epoch 178/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0275 - val_loss: 0.0961\n",
      "Epoch 179/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0270 - val_loss: 0.0977\n",
      "Epoch 180/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0241 - val_loss: 0.0930\n",
      "Epoch 181/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0238 - val_loss: 0.0939\n",
      "Epoch 182/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0237 - val_loss: 0.0948\n",
      "Epoch 183/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0250 - val_loss: 0.0957\n",
      "Epoch 184/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0244 - val_loss: 0.0947\n",
      "Epoch 185/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0240 - val_loss: 0.0964\n",
      "Epoch 186/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0237 - val_loss: 0.0962\n",
      "Epoch 187/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0233 - val_loss: 0.0940\n",
      "Epoch 188/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0239 - val_loss: 0.0924\n",
      "Epoch 189/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0258 - val_loss: 0.1057\n",
      "Epoch 190/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0264 - val_loss: 0.0925\n",
      "Epoch 191/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0256 - val_loss: 0.1080\n",
      "Epoch 192/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0247 - val_loss: 0.0956\n",
      "Epoch 193/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0220 - val_loss: 0.0949\n",
      "Epoch 194/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0219 - val_loss: 0.1005\n",
      "Epoch 195/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0209 - val_loss: 0.0941\n",
      "Epoch 196/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0230 - val_loss: 0.0996\n",
      "Epoch 197/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0213 - val_loss: 0.0932\n",
      "Epoch 198/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0222 - val_loss: 0.0941\n",
      "Epoch 199/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0213 - val_loss: 0.0963\n",
      "Epoch 200/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0220 - val_loss: 0.1013\n",
      "Epoch 201/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0209 - val_loss: 0.1003\n",
      "Epoch 202/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0212 - val_loss: 0.1014\n",
      "Epoch 203/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0209 - val_loss: 0.0965\n",
      "Epoch 204/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0206 - val_loss: 0.1061\n",
      "Epoch 205/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0238 - val_loss: 0.0953\n",
      "Epoch 206/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0233 - val_loss: 0.1013\n",
      "Epoch 207/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0255 - val_loss: 0.1013\n",
      "Epoch 208/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0234 - val_loss: 0.0942\n",
      "Epoch 209/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0213 - val_loss: 0.0956\n",
      "Epoch 210/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0204 - val_loss: 0.0957\n",
      "Epoch 211/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0193 - val_loss: 0.0937\n",
      "Epoch 212/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0192 - val_loss: 0.0984\n",
      "Epoch 213/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0190 - val_loss: 0.0960\n",
      "Epoch 214/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0192 - val_loss: 0.0950\n",
      "Epoch 215/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0200 - val_loss: 0.0966\n",
      "Epoch 216/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0204 - val_loss: 0.0940\n",
      "Epoch 217/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0183 - val_loss: 0.1009\n",
      "Epoch 218/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0186 - val_loss: 0.0984\n",
      "Epoch 219/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0188 - val_loss: 0.0955\n",
      "Epoch 220/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0194 - val_loss: 0.0995\n",
      "Epoch 221/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0194 - val_loss: 0.0936\n",
      "Epoch 222/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0187 - val_loss: 0.0914\n",
      "Epoch 223/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0185 - val_loss: 0.0900\n",
      "Epoch 224/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0227 - val_loss: 0.1106\n",
      "Epoch 225/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0235 - val_loss: 0.0888\n",
      "Epoch 226/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0234 - val_loss: 0.0909\n",
      "Epoch 227/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0186 - val_loss: 0.1009\n",
      "Epoch 228/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0200 - val_loss: 0.1031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0184 - val_loss: 0.0959\n",
      "Epoch 230/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0201 - val_loss: 0.0980\n",
      "Epoch 231/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0168 - val_loss: 0.0920\n",
      "Epoch 232/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0168 - val_loss: 0.0897\n",
      "Epoch 233/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0168 - val_loss: 0.0894\n",
      "Epoch 234/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0170 - val_loss: 0.0934\n",
      "Epoch 235/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0170 - val_loss: 0.0953\n",
      "Epoch 236/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0177 - val_loss: 0.0964\n",
      "Epoch 237/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0184 - val_loss: 0.0969\n",
      "Epoch 238/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0161 - val_loss: 0.0978\n",
      "Epoch 239/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0171 - val_loss: 0.1035\n",
      "Epoch 240/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0159 - val_loss: 0.0917\n",
      "Epoch 241/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0171 - val_loss: 0.0912\n",
      "Epoch 242/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0164 - val_loss: 0.0970\n",
      "Epoch 243/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0165 - val_loss: 0.0945\n",
      "Epoch 244/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0155 - val_loss: 0.0986\n",
      "Epoch 245/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0161 - val_loss: 0.0953\n",
      "Epoch 246/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0173 - val_loss: 0.0940\n",
      "Epoch 247/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0162 - val_loss: 0.0948\n",
      "Epoch 248/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0160 - val_loss: 0.1008\n",
      "Epoch 249/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0188 - val_loss: 0.0931\n",
      "Epoch 250/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0157 - val_loss: 0.1012\n",
      "Epoch 251/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0150 - val_loss: 0.0943\n",
      "Epoch 252/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0155 - val_loss: 0.0970\n",
      "Epoch 253/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0168 - val_loss: 0.1075\n",
      "Epoch 254/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0155 - val_loss: 0.0904\n",
      "Epoch 255/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0149 - val_loss: 0.0996\n",
      "Epoch 256/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0148 - val_loss: 0.0942\n",
      "Epoch 257/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0146 - val_loss: 0.0976\n",
      "Epoch 258/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0140 - val_loss: 0.1013\n",
      "Epoch 259/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0157 - val_loss: 0.0944\n",
      "Epoch 260/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0165 - val_loss: 0.0956\n",
      "Epoch 261/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0142 - val_loss: 0.0964\n",
      "Epoch 262/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0137 - val_loss: 0.0977\n",
      "Epoch 263/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0156 - val_loss: 0.1033\n",
      "Epoch 264/600\n",
      "426/426 [==============================] - 0s 52us/sample - loss: 0.0139 - val_loss: 0.0934\n",
      "Epoch 265/600\n",
      "426/426 [==============================] - 0s 48us/sample - loss: 0.0148 - val_loss: 0.1001\n",
      "Epoch 266/600\n",
      "426/426 [==============================] - 0s 43us/sample - loss: 0.0155 - val_loss: 0.1003\n",
      "Epoch 267/600\n",
      "426/426 [==============================] - 0s 67us/sample - loss: 0.0149 - val_loss: 0.0920\n",
      "Epoch 268/600\n",
      "426/426 [==============================] - 0s 48us/sample - loss: 0.0160 - val_loss: 0.1014\n",
      "Epoch 269/600\n",
      "426/426 [==============================] - 0s 67us/sample - loss: 0.0143 - val_loss: 0.0914\n",
      "Epoch 270/600\n",
      "426/426 [==============================] - 0s 53us/sample - loss: 0.0135 - val_loss: 0.0978\n",
      "Epoch 271/600\n",
      "426/426 [==============================] - 0s 66us/sample - loss: 0.0137 - val_loss: 0.0993\n",
      "Epoch 272/600\n",
      "426/426 [==============================] - 0s 43us/sample - loss: 0.0136 - val_loss: 0.0990\n",
      "Epoch 273/600\n",
      "426/426 [==============================] - 0s 64us/sample - loss: 0.0137 - val_loss: 0.0980\n",
      "Epoch 274/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0130 - val_loss: 0.0937\n",
      "Epoch 275/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0129 - val_loss: 0.0951\n",
      "Epoch 276/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.006 - 0s 56us/sample - loss: 0.0127 - val_loss: 0.0936\n",
      "Epoch 277/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0135 - val_loss: 0.0973\n",
      "Epoch 278/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0125 - val_loss: 0.0980\n",
      "Epoch 279/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0138 - val_loss: 0.0948\n",
      "Epoch 280/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0141 - val_loss: 0.0986\n",
      "Epoch 281/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0121 - val_loss: 0.0986\n",
      "Epoch 282/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0137 - val_loss: 0.0951\n",
      "Epoch 283/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0125 - val_loss: 0.0905\n",
      "Epoch 284/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0140 - val_loss: 0.0980\n",
      "Epoch 285/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0125 - val_loss: 0.0991\n",
      "Epoch 286/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0127 - val_loss: 0.0989\n",
      "Epoch 287/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0153 - val_loss: 0.0970\n",
      "Epoch 288/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0145 - val_loss: 0.1082\n",
      "Epoch 289/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0118 - val_loss: 0.1006\n",
      "Epoch 290/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0126 - val_loss: 0.1049\n",
      "Epoch 291/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0127 - val_loss: 0.0988\n",
      "Epoch 292/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.0993\n",
      "Epoch 293/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0116 - val_loss: 0.0983\n",
      "Epoch 294/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0129 - val_loss: 0.0982\n",
      "Epoch 295/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0107 - val_loss: 0.1135\n",
      "Epoch 296/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0149 - val_loss: 0.0987\n",
      "Epoch 297/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0111 - val_loss: 0.0972\n",
      "Epoch 298/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0111 - val_loss: 0.0950\n",
      "Epoch 299/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0115 - val_loss: 0.0986\n",
      "Epoch 300/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0112 - val_loss: 0.1055\n",
      "Epoch 301/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0107 - val_loss: 0.1054\n",
      "Epoch 302/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0105 - val_loss: 0.1004\n",
      "Epoch 303/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0110 - val_loss: 0.1028\n",
      "Epoch 304/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0105 - val_loss: 0.1014\n",
      "Epoch 305/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0113 - val_loss: 0.1154\n",
      "Epoch 306/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0120 - val_loss: 0.1041\n",
      "Epoch 307/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0121 - val_loss: 0.1056\n",
      "Epoch 308/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0148 - val_loss: 0.1094\n",
      "Epoch 309/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0142 - val_loss: 0.1137\n",
      "Epoch 310/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0130 - val_loss: 0.1044\n",
      "Epoch 311/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0129 - val_loss: 0.1071\n",
      "Epoch 312/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0113 - val_loss: 0.1072\n",
      "Epoch 313/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0108 - val_loss: 0.1081\n",
      "Epoch 314/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0101 - val_loss: 0.1030\n",
      "Epoch 315/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0103 - val_loss: 0.1057\n",
      "Epoch 316/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0115 - val_loss: 0.1082\n",
      "Epoch 317/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0103 - val_loss: 0.1096\n",
      "Epoch 318/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0106 - val_loss: 0.1077\n",
      "Epoch 319/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0145 - val_loss: 0.1318\n",
      "Epoch 320/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0158 - val_loss: 0.0981\n",
      "Epoch 321/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0092 - val_loss: 0.1039\n",
      "Epoch 322/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0095 - val_loss: 0.1044\n",
      "Epoch 323/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0094 - val_loss: 0.1093\n",
      "Epoch 324/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0096 - val_loss: 0.1070\n",
      "Epoch 325/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0088 - val_loss: 0.1133\n",
      "Epoch 326/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0098 - val_loss: 0.1150\n",
      "Epoch 327/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0109 - val_loss: 0.1103\n",
      "Epoch 328/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0141 - val_loss: 0.1290\n",
      "Epoch 329/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0106 - val_loss: 0.1113\n",
      "Epoch 330/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0098 - val_loss: 0.1132\n",
      "Epoch 331/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0095 - val_loss: 0.1139\n",
      "Epoch 332/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0098 - val_loss: 0.1060\n",
      "Epoch 333/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0098 - val_loss: 0.1086\n",
      "Epoch 334/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0085 - val_loss: 0.1134\n",
      "Epoch 335/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0090 - val_loss: 0.1114\n",
      "Epoch 336/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0098 - val_loss: 0.1132\n",
      "Epoch 337/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0105 - val_loss: 0.1188\n",
      "Epoch 338/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0096 - val_loss: 0.1132\n",
      "Epoch 339/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0086 - val_loss: 0.1159\n",
      "Epoch 340/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0087 - val_loss: 0.1124\n",
      "Epoch 341/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0087 - val_loss: 0.1120\n",
      "Epoch 342/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0088 - val_loss: 0.1225\n",
      "Epoch 343/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0097 - val_loss: 0.1192\n",
      "Epoch 344/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0081 - val_loss: 0.1165\n",
      "Epoch 345/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0084 - val_loss: 0.1193\n",
      "Epoch 346/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0080 - val_loss: 0.1176\n",
      "Epoch 347/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0084 - val_loss: 0.1206\n",
      "Epoch 348/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0091 - val_loss: 0.1113\n",
      "Epoch 349/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0084 - val_loss: 0.1226\n",
      "Epoch 350/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0088 - val_loss: 0.1161\n",
      "Epoch 351/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0111 - val_loss: 0.1199\n",
      "Epoch 352/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0087 - val_loss: 0.1276\n",
      "Epoch 353/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0082 - val_loss: 0.1209\n",
      "Epoch 354/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0083 - val_loss: 0.1292\n",
      "Epoch 355/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0101 - val_loss: 0.1193\n",
      "Epoch 356/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0090 - val_loss: 0.1196\n",
      "Epoch 357/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0093 - val_loss: 0.1227\n",
      "Epoch 358/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0075 - val_loss: 0.1216\n",
      "Epoch 359/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0077 - val_loss: 0.1280\n",
      "Epoch 360/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.1208\n",
      "Epoch 361/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0097 - val_loss: 0.1276\n",
      "Epoch 362/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0095 - val_loss: 0.1263\n",
      "Epoch 363/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0087 - val_loss: 0.1248\n",
      "Epoch 364/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0093 - val_loss: 0.1260\n",
      "Epoch 365/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0150 - val_loss: 0.1285\n",
      "Epoch 366/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0095 - val_loss: 0.1309\n",
      "Epoch 367/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0104 - val_loss: 0.1216\n",
      "Epoch 368/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0124 - val_loss: 0.1460\n",
      "Epoch 369/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0078 - val_loss: 0.1268\n",
      "Epoch 370/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0075 - val_loss: 0.1275\n",
      "Epoch 371/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0091 - val_loss: 0.1290\n",
      "Epoch 372/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0074 - val_loss: 0.1412\n",
      "Epoch 373/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0077 - val_loss: 0.1344\n",
      "Epoch 374/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0076 - val_loss: 0.1393\n",
      "Epoch 375/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0081 - val_loss: 0.1350\n",
      "Epoch 376/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0103 - val_loss: 0.1344\n",
      "Epoch 377/600\n",
      "426/426 [==============================] - 0s 57us/sample - loss: 0.0116 - val_loss: 0.1300\n",
      "Epoch 378/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0084 - val_loss: 0.1385\n",
      "Epoch 379/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0095 - val_loss: 0.1257\n",
      "Epoch 380/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0141 - val_loss: 0.1409\n",
      "Epoch 381/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0097 - val_loss: 0.1290\n",
      "Epoch 382/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0074 - val_loss: 0.1238\n",
      "Epoch 383/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0078 - val_loss: 0.1272\n",
      "Epoch 384/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0078 - val_loss: 0.1305\n",
      "Epoch 385/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0066 - val_loss: 0.1243\n",
      "Epoch 386/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0066 - val_loss: 0.1379\n",
      "Epoch 387/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0080 - val_loss: 0.1299\n",
      "Epoch 388/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0070 - val_loss: 0.1336\n",
      "Epoch 389/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0066 - val_loss: 0.1308\n",
      "Epoch 390/600\n",
      "426/426 [==============================] - 0s 37us/sample - loss: 0.0059 - val_loss: 0.1352\n",
      "Epoch 391/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0060 - val_loss: 0.1356\n",
      "Epoch 392/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0067 - val_loss: 0.1411\n",
      "Epoch 393/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0068 - val_loss: 0.1345\n",
      "Epoch 394/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0067 - val_loss: 0.1344\n",
      "Epoch 395/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0063 - val_loss: 0.1457\n",
      "Epoch 396/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0074 - val_loss: 0.1466\n",
      "Epoch 397/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0068 - val_loss: 0.1403\n",
      "Epoch 398/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0058 - val_loss: 0.1388\n",
      "Epoch 399/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0071 - val_loss: 0.1413\n",
      "Epoch 400/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0103 - val_loss: 0.1391\n",
      "Epoch 401/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0087 - val_loss: 0.1543\n",
      "Epoch 402/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0077 - val_loss: 0.1438\n",
      "Epoch 403/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0095 - val_loss: 0.1488\n",
      "Epoch 404/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0061 - val_loss: 0.1309\n",
      "Epoch 405/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0069 - val_loss: 0.1432\n",
      "Epoch 406/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0056 - val_loss: 0.1382\n",
      "Epoch 407/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0058 - val_loss: 0.1395\n",
      "Epoch 408/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0054 - val_loss: 0.1462\n",
      "Epoch 409/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0052 - val_loss: 0.1409\n",
      "Epoch 410/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0053 - val_loss: 0.1425\n",
      "Epoch 411/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0062 - val_loss: 0.1386\n",
      "Epoch 412/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0068 - val_loss: 0.1423\n",
      "Epoch 413/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0055 - val_loss: 0.1417\n",
      "Epoch 414/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0057 - val_loss: 0.1426\n",
      "Epoch 415/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0055 - val_loss: 0.1409\n",
      "Epoch 416/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0051 - val_loss: 0.1427\n",
      "Epoch 417/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0055 - val_loss: 0.1383\n",
      "Epoch 418/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0055 - val_loss: 0.1408\n",
      "Epoch 419/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0074 - val_loss: 0.1458\n",
      "Epoch 420/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0056 - val_loss: 0.1476\n",
      "Epoch 421/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0061 - val_loss: 0.1456\n",
      "Epoch 422/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0066 - val_loss: 0.1470\n",
      "Epoch 423/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0052 - val_loss: 0.1489\n",
      "Epoch 424/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0049 - val_loss: 0.1523\n",
      "Epoch 425/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0051 - val_loss: 0.1573\n",
      "Epoch 426/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0062 - val_loss: 0.1494\n",
      "Epoch 427/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0052 - val_loss: 0.1437\n",
      "Epoch 428/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0049 - val_loss: 0.1477\n",
      "Epoch 429/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0064 - val_loss: 0.1540\n",
      "Epoch 430/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0063 - val_loss: 0.1425\n",
      "Epoch 431/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0052 - val_loss: 0.1430\n",
      "Epoch 432/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0068 - val_loss: 0.1483\n",
      "Epoch 433/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0057 - val_loss: 0.1562\n",
      "Epoch 434/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0065 - val_loss: 0.1653\n",
      "Epoch 435/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0085 - val_loss: 0.1519\n",
      "Epoch 436/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0049 - val_loss: 0.1535\n",
      "Epoch 437/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0047 - val_loss: 0.1535\n",
      "Epoch 438/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0043 - val_loss: 0.1560\n",
      "Epoch 439/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0044 - val_loss: 0.1570\n",
      "Epoch 440/600\n",
      "426/426 [==============================] - 0s 38us/sample - loss: 0.0044 - val_loss: 0.1558\n",
      "Epoch 441/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0044 - val_loss: 0.1572\n",
      "Epoch 442/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0044 - val_loss: 0.1612\n",
      "Epoch 443/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0051 - val_loss: 0.1626\n",
      "Epoch 444/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0054 - val_loss: 0.1692\n",
      "Epoch 445/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0060 - val_loss: 0.1557\n",
      "Epoch 446/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0044 - val_loss: 0.1522\n",
      "Epoch 447/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0042 - val_loss: 0.1566\n",
      "Epoch 448/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0047 - val_loss: 0.1571\n",
      "Epoch 449/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0049 - val_loss: 0.1631\n",
      "Epoch 450/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0053 - val_loss: 0.1663\n",
      "Epoch 451/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0046 - val_loss: 0.1584\n",
      "Epoch 452/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0041 - val_loss: 0.1589\n",
      "Epoch 453/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0040 - val_loss: 0.1631\n",
      "Epoch 454/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0038 - val_loss: 0.1644\n",
      "Epoch 455/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0040 - val_loss: 0.1648\n",
      "Epoch 456/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0051 - val_loss: 0.1723\n",
      "Epoch 457/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0049 - val_loss: 0.1641\n",
      "Epoch 458/600\n",
      "426/426 [==============================] - 0s 57us/sample - loss: 0.0039 - val_loss: 0.1670\n",
      "Epoch 459/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1682\n",
      "Epoch 460/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0038 - val_loss: 0.1708\n",
      "Epoch 461/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0041 - val_loss: 0.1712\n",
      "Epoch 462/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1702\n",
      "Epoch 463/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0037 - val_loss: 0.1713\n",
      "Epoch 464/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0038 - val_loss: 0.1717\n",
      "Epoch 465/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.1709\n",
      "Epoch 466/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1706\n",
      "Epoch 467/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0043 - val_loss: 0.1694\n",
      "Epoch 468/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.1690\n",
      "Epoch 469/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.1740\n",
      "Epoch 470/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0044 - val_loss: 0.1736\n",
      "Epoch 471/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0044 - val_loss: 0.1738\n",
      "Epoch 472/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0035 - val_loss: 0.1814\n",
      "Epoch 473/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0048 - val_loss: 0.1777\n",
      "Epoch 474/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0053 - val_loss: 0.1647\n",
      "Epoch 475/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0050 - val_loss: 0.1769\n",
      "Epoch 476/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0048 - val_loss: 0.1848\n",
      "Epoch 477/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.1789\n",
      "Epoch 478/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0034 - val_loss: 0.1741\n",
      "Epoch 479/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0033 - val_loss: 0.1728\n",
      "Epoch 480/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0033 - val_loss: 0.1746\n",
      "Epoch 481/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1760\n",
      "Epoch 482/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0033 - val_loss: 0.1763\n",
      "Epoch 483/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0034 - val_loss: 0.1763\n",
      "Epoch 484/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.1741\n",
      "Epoch 485/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0032 - val_loss: 0.1796\n",
      "Epoch 486/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0047 - val_loss: 0.1946\n",
      "Epoch 487/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0043 - val_loss: 0.1944\n",
      "Epoch 488/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0046 - val_loss: 0.2004\n",
      "Epoch 489/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0039 - val_loss: 0.2001\n",
      "Epoch 490/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0049 - val_loss: 0.1852\n",
      "Epoch 491/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0070 - val_loss: 0.1702\n",
      "Epoch 492/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0048 - val_loss: 0.1886\n",
      "Epoch 493/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0044 - val_loss: 0.1823\n",
      "Epoch 494/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1883\n",
      "Epoch 495/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0040 - val_loss: 0.1857\n",
      "Epoch 496/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0044 - val_loss: 0.1827\n",
      "Epoch 497/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0038 - val_loss: 0.1847\n",
      "Epoch 498/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0033 - val_loss: 0.1785\n",
      "Epoch 499/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0034 - val_loss: 0.1786\n",
      "Epoch 500/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0031 - val_loss: 0.1831\n",
      "Epoch 501/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0029 - val_loss: 0.1854\n",
      "Epoch 502/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0028 - val_loss: 0.1872\n",
      "Epoch 503/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0029 - val_loss: 0.1883\n",
      "Epoch 504/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0030 - val_loss: 0.1898\n",
      "Epoch 505/600\n",
      "426/426 [==============================] - 0s 113us/sample - loss: 0.0034 - val_loss: 0.1874\n",
      "Epoch 506/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0027 - val_loss: 0.1929\n",
      "Epoch 507/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0033 - val_loss: 0.1925\n",
      "Epoch 508/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0027 - val_loss: 0.1930\n",
      "Epoch 509/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0045 - val_loss: 0.1852\n",
      "Epoch 510/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0029 - val_loss: 0.1906\n",
      "Epoch 511/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0030 - val_loss: 0.1891\n",
      "Epoch 512/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0032 - val_loss: 0.1868\n",
      "Epoch 513/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0074 - val_loss: 0.1944\n",
      "Epoch 514/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0068 - val_loss: 0.2048\n",
      "Epoch 515/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0035 - val_loss: 0.1879\n",
      "Epoch 516/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0032 - val_loss: 0.1897\n",
      "Epoch 517/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0028 - val_loss: 0.1968\n",
      "Epoch 518/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0033 - val_loss: 0.1953\n",
      "Epoch 519/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0035 - val_loss: 0.1971\n",
      "Epoch 520/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0030 - val_loss: 0.1959\n",
      "Epoch 521/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0027 - val_loss: 0.1939\n",
      "Epoch 522/600\n",
      "426/426 [==============================] - 0s 94us/sample - loss: 0.0034 - val_loss: 0.1987\n",
      "Epoch 523/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0029 - val_loss: 0.1957\n",
      "Epoch 524/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0029 - val_loss: 0.1988\n",
      "Epoch 525/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0029 - val_loss: 0.2046\n",
      "Epoch 526/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0028 - val_loss: 0.2002\n",
      "Epoch 527/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0025 - val_loss: 0.1999\n",
      "Epoch 528/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0024 - val_loss: 0.1994\n",
      "Epoch 529/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0027 - val_loss: 0.2013\n",
      "Epoch 530/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.2004\n",
      "Epoch 531/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0027 - val_loss: 0.2098\n",
      "Epoch 532/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.2064\n",
      "Epoch 533/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0059 - val_loss: 0.2527\n",
      "Epoch 534/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0077 - val_loss: 0.2200\n",
      "Epoch 535/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0240 - val_loss: 0.2062\n",
      "Epoch 536/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0160 - val_loss: 0.1819\n",
      "Epoch 537/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0045 - val_loss: 0.1873\n",
      "Epoch 538/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.2072\n",
      "Epoch 539/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0039 - val_loss: 0.1998\n",
      "Epoch 540/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.1982\n",
      "Epoch 541/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0023 - val_loss: 0.1958\n",
      "Epoch 542/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0023 - val_loss: 0.1995\n",
      "Epoch 543/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0023 - val_loss: 0.2004\n",
      "Epoch 544/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0024 - val_loss: 0.2028\n",
      "Epoch 545/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0023 - val_loss: 0.2041\n",
      "Epoch 546/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0025 - val_loss: 0.2042\n",
      "Epoch 547/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0022 - val_loss: 0.2047\n",
      "Epoch 548/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0023 - val_loss: 0.2055\n",
      "Epoch 549/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0021 - val_loss: 0.2031\n",
      "Epoch 550/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0022 - val_loss: 0.2043\n",
      "Epoch 551/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0022 - val_loss: 0.2093\n",
      "Epoch 552/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0022 - val_loss: 0.2097\n",
      "Epoch 553/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0022 - val_loss: 0.2066\n",
      "Epoch 554/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0025 - val_loss: 0.2041\n",
      "Epoch 555/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0029 - val_loss: 0.2014\n",
      "Epoch 556/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0033 - val_loss: 0.2028\n",
      "Epoch 557/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0037 - val_loss: 0.2084\n",
      "Epoch 558/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0021 - val_loss: 0.2118\n",
      "Epoch 559/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2105\n",
      "Epoch 560/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0022 - val_loss: 0.2107\n",
      "Epoch 561/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0019 - val_loss: 0.2122\n",
      "Epoch 562/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2135\n",
      "Epoch 563/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2149\n",
      "Epoch 564/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2149\n",
      "Epoch 565/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0022 - val_loss: 0.2138\n",
      "Epoch 566/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0019 - val_loss: 0.2163\n",
      "Epoch 567/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0019 - val_loss: 0.2200\n",
      "Epoch 568/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2185\n",
      "Epoch 569/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2189\n",
      "Epoch 570/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0019 - val_loss: 0.2199\n",
      "Epoch 571/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2223\n",
      "Epoch 572/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 3.2480e-0 - 0s 75us/sample - loss: 0.0020 - val_loss: 0.2242\n",
      "Epoch 573/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.2217\n",
      "Epoch 574/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0019 - val_loss: 0.2209\n",
      "Epoch 575/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.2249\n",
      "Epoch 576/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2278\n",
      "Epoch 577/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.2277\n",
      "Epoch 578/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0018 - val_loss: 0.2245\n",
      "Epoch 579/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2253\n",
      "Epoch 580/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0020 - val_loss: 0.2274\n",
      "Epoch 581/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0021 - val_loss: 0.2301\n",
      "Epoch 582/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0026 - val_loss: 0.2313\n",
      "Epoch 583/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0052 - val_loss: 0.2595\n",
      "Epoch 584/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0041 - val_loss: 0.2501\n",
      "Epoch 585/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0042 - val_loss: 0.2173\n",
      "Epoch 586/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0021 - val_loss: 0.2142\n",
      "Epoch 587/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0017 - val_loss: 0.2198\n",
      "Epoch 588/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0018 - val_loss: 0.2193\n",
      "Epoch 589/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0033 - val_loss: 0.2310\n",
      "Epoch 590/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0026 - val_loss: 0.2358\n",
      "Epoch 591/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0058 - val_loss: 0.2893\n",
      "Epoch 592/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0258 - val_loss: 0.2294\n",
      "Epoch 593/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0142 - val_loss: 0.2044\n",
      "Epoch 594/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0067 - val_loss: 0.1963\n",
      "Epoch 595/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0020 - val_loss: 0.1987\n",
      "Epoch 596/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0021 - val_loss: 0.1970\n",
      "Epoch 597/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0019 - val_loss: 0.1976\n",
      "Epoch 598/600\n",
      "426/426 [==============================] - 0s 75us/sample - loss: 0.0021 - val_loss: 0.2010\n",
      "Epoch 599/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.2008\n",
      "Epoch 600/600\n",
      "426/426 [==============================] - 0s 56us/sample - loss: 0.0018 - val_loss: 0.2010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158a0f47400>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x158a2e49518>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect example of overfit to avoid it we'll apply early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "\n",
    "model.add(Dense(15,activation='relu'))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EarlyStopping in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "class EarlyStopping(Callback)\n",
      " |  EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |  \n",
      " |  Stop training when a monitored quantity has stopped improving.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      monitor: Quantity to be monitored.\n",
      " |      min_delta: Minimum change in the monitored quantity\n",
      " |          to qualify as an improvement, i.e. an absolute\n",
      " |          change of less than min_delta, will count as no\n",
      " |          improvement.\n",
      " |      patience: Number of epochs with no improvement\n",
      " |          after which training will be stopped.\n",
      " |      verbose: verbosity mode.\n",
      " |      mode: One of `{\"auto\", \"min\", \"max\"}`. In `min` mode,\n",
      " |          training will stop when the quantity\n",
      " |          monitored has stopped decreasing; in `max`\n",
      " |          mode it will stop when the quantity\n",
      " |          monitored has stopped increasing; in `auto`\n",
      " |          mode, the direction is automatically inferred\n",
      " |          from the name of the monitored quantity.\n",
      " |      baseline: Baseline value for the monitored quantity.\n",
      " |          Training will stop if the model doesn't show improvement over the\n",
      " |          baseline.\n",
      " |      restore_best_weights: Whether to restore model weights from\n",
      " |          the epoch with the best value of the monitored quantity.\n",
      " |          If False, the model weights obtained at the last step of\n",
      " |          training are used.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
      " |  # This callback will stop the training when there is no improvement in\n",
      " |  # the validation loss for three consecutive epochs.\n",
      " |  model.fit(data, labels, epochs=100, callbacks=[callback],\n",
      " |      validation_data=(val_data, val_labels))\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EarlyStopping\n",
      " |      Callback\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_monitor_value(self, logs)\n",
      " |  \n",
      " |  on_epoch_end(self, epoch, logs=None)\n",
      " |      Called at the end of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          epoch: integer, index of epoch.\n",
      " |          logs: dict, metric results for this training epoch, and for the\n",
      " |            validation epoch if validation is performed. Validation result keys\n",
      " |            are prefixed with `val_`.\n",
      " |  \n",
      " |  on_train_begin(self, logs=None)\n",
      " |      Called at the beginning of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_end(self, logs=None)\n",
      " |      Called at the end of training.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Callback:\n",
      " |  \n",
      " |  on_batch_begin(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_begin`.\n",
      " |  \n",
      " |  on_batch_end(self, batch, logs=None)\n",
      " |      A backwards compatibility alias for `on_train_batch_end`.\n",
      " |  \n",
      " |  on_epoch_begin(self, epoch, logs=None)\n",
      " |      Called at the start of an epoch.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run. This function should only\n",
      " |      be called during TRAIN mode.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          epoch: integer, index of epoch.\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Has keys `batch` and `size` representing the current batch\n",
      " |            number and the size of the batch.\n",
      " |  \n",
      " |  on_predict_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `predict` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Metric results for this batch.\n",
      " |  \n",
      " |  on_predict_begin(self, logs=None)\n",
      " |      Called at the beginning of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_predict_end(self, logs=None)\n",
      " |      Called at the end of prediction.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the beginning of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Has keys `batch` and `size` representing the current batch\n",
      " |            number and the size of the batch.\n",
      " |  \n",
      " |  on_test_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a batch in `evaluate` methods.\n",
      " |      \n",
      " |      Also called at the end of a validation batch in the `fit`\n",
      " |      methods, if validation data is provided.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Metric results for this batch.\n",
      " |  \n",
      " |  on_test_begin(self, logs=None)\n",
      " |      Called at the beginning of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_test_end(self, logs=None)\n",
      " |      Called at the end of evaluation or validation.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          logs: dict. Currently no data is passed to this argument for this method\n",
      " |            but that may change in the future.\n",
      " |  \n",
      " |  on_train_batch_begin(self, batch, logs=None)\n",
      " |      Called at the beginning of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Has keys `batch` and `size` representing the current batch\n",
      " |            number and the size of the batch.\n",
      " |  \n",
      " |  on_train_batch_end(self, batch, logs=None)\n",
      " |      Called at the end of a training batch in `fit` methods.\n",
      " |      \n",
      " |      Subclasses should override for any actions to run.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          batch: integer, index of batch within the current epoch.\n",
      " |          logs: dict. Metric results for this batch.\n",
      " |  \n",
      " |  set_model(self, model)\n",
      " |  \n",
      " |  set_params(self, params)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from Callback:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(EarlyStopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 1s 3ms/sample - loss: 0.6727 - val_loss: 0.6570\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 103us/sample - loss: 0.6404 - val_loss: 0.6275\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 112us/sample - loss: 0.6042 - val_loss: 0.5894\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 116us/sample - loss: 0.5586 - val_loss: 0.5406\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 135us/sample - loss: 0.5100 - val_loss: 0.4882\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 135us/sample - loss: 0.4602 - val_loss: 0.4381\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 111us/sample - loss: 0.4137 - val_loss: 0.3873\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 128us/sample - loss: 0.3672 - val_loss: 0.3422\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 101us/sample - loss: 0.3289 - val_loss: 0.3056\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 149us/sample - loss: 0.2973 - val_loss: 0.2791\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 194us/sample - loss: 0.2719 - val_loss: 0.2495\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.2517 - val_loss: 0.2296\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 228us/sample - loss: 0.2314 - val_loss: 0.2146\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 198us/sample - loss: 0.2169 - val_loss: 0.1989\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 219us/sample - loss: 0.2039 - val_loss: 0.1936\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 210us/sample - loss: 0.1933 - val_loss: 0.1776\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 209us/sample - loss: 0.1821 - val_loss: 0.1730\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 234us/sample - loss: 0.1757 - val_loss: 0.1650\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 211us/sample - loss: 0.1650 - val_loss: 0.1602\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.1558 - val_loss: 0.1519\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 224us/sample - loss: 0.1495 - val_loss: 0.1473\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 208us/sample - loss: 0.1424 - val_loss: 0.1456\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 213us/sample - loss: 0.1359 - val_loss: 0.1420\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 202us/sample - loss: 0.1293 - val_loss: 0.1362\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.1227 - val_loss: 0.1353\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 218us/sample - loss: 0.1202 - val_loss: 0.1322\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 215us/sample - loss: 0.1147 - val_loss: 0.1254\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 215us/sample - loss: 0.1088 - val_loss: 0.1255\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 189us/sample - loss: 0.1042 - val_loss: 0.1236\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 229us/sample - loss: 0.1038 - val_loss: 0.1226\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 222us/sample - loss: 0.0974 - val_loss: 0.1216\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 248us/sample - loss: 0.0944 - val_loss: 0.1160\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 252us/sample - loss: 0.0910 - val_loss: 0.1177\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 250us/sample - loss: 0.0872 - val_loss: 0.1141\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 226us/sample - loss: 0.0853 - val_loss: 0.1154\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 93us/sample - loss: 0.0823 - val_loss: 0.1115\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 108us/sample - loss: 0.0823 - val_loss: 0.1126\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.0813 - val_loss: 0.1155\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.0787 - val_loss: 0.1109\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0752 - val_loss: 0.1092\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 134us/sample - loss: 0.0751 - val_loss: 0.1107\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.0724 - val_loss: 0.1079\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.0713 - val_loss: 0.1127\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.0704 - val_loss: 0.1069\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 149us/sample - loss: 0.0695 - val_loss: 0.1095\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 170us/sample - loss: 0.0749 - val_loss: 0.1064\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 169us/sample - loss: 0.0678 - val_loss: 0.1086\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.0671 - val_loss: 0.1117\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 151us/sample - loss: 0.0644 - val_loss: 0.1080\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 160us/sample - loss: 0.0636 - val_loss: 0.1079\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.0647 - val_loss: 0.1098\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 132us/sample - loss: 0.0621 - val_loss: 0.1109\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 158us/sample - loss: 0.0615 - val_loss: 0.1081\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.0652 - val_loss: 0.1175\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0628 - val_loss: 0.1048\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.0640 - val_loss: 0.1104\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.0592 - val_loss: 0.1075\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.0579 - val_loss: 0.1057\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 173us/sample - loss: 0.0573 - val_loss: 0.1065\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 151us/sample - loss: 0.0578 - val_loss: 0.1142\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 178us/sample - loss: 0.0574 - val_loss: 0.1056\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 175us/sample - loss: 0.0593 - val_loss: 0.1125\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 181us/sample - loss: 0.0654 - val_loss: 0.1053\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 176us/sample - loss: 0.0593 - val_loss: 0.1092\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 173us/sample - loss: 0.0553 - val_loss: 0.1106\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 181us/sample - loss: 0.0573 - val_loss: 0.1042\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 200us/sample - loss: 0.0568 - val_loss: 0.1079\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 170us/sample - loss: 0.0529 - val_loss: 0.1045\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 193us/sample - loss: 0.0541 - val_loss: 0.1105\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 186us/sample - loss: 0.0553 - val_loss: 0.1137\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 172us/sample - loss: 0.0530 - val_loss: 0.1064\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 217us/sample - loss: 0.0520 - val_loss: 0.1074\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 188us/sample - loss: 0.0526 - val_loss: 0.1068\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 178us/sample - loss: 0.0519 - val_loss: 0.1120\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 183us/sample - loss: 0.0512 - val_loss: 0.1065\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 195us/sample - loss: 0.0505 - val_loss: 0.1089\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 190us/sample - loss: 0.0511 - val_loss: 0.1093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "426/426 [==============================] - 0s 206us/sample - loss: 0.0500 - val_loss: 0.1061\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 205us/sample - loss: 0.0493 - val_loss: 0.1143\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 203us/sample - loss: 0.0517 - val_loss: 0.1073\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 215us/sample - loss: 0.0503 - val_loss: 0.1077\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.0483 - val_loss: 0.1231\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.0513 - val_loss: 0.1081\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.0506 - val_loss: 0.1116\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 128us/sample - loss: 0.0475 - val_loss: 0.1158\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.0488 - val_loss: 0.1076\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 130us/sample - loss: 0.0510 - val_loss: 0.1145\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0492 - val_loss: 0.1100\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.0494 - val_loss: 0.1135\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 114us/sample - loss: 0.0466 - val_loss: 0.1099\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0464 - val_loss: 0.1126\n",
      "Epoch 00091: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158ad0a3e10>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x158ae4ac8d0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(15,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 426 samples, validate on 143 samples\n",
      "Epoch 1/600\n",
      "426/426 [==============================] - 1s 3ms/sample - loss: 0.7039 - val_loss: 0.6852\n",
      "Epoch 2/600\n",
      "426/426 [==============================] - 0s 104us/sample - loss: 0.6869 - val_loss: 0.6797\n",
      "Epoch 3/600\n",
      "426/426 [==============================] - 0s 124us/sample - loss: 0.6801 - val_loss: 0.6753\n",
      "Epoch 4/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.6697 - val_loss: 0.6679\n",
      "Epoch 5/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.6632 - val_loss: 0.6517\n",
      "Epoch 6/600\n",
      "426/426 [==============================] - 0s 134us/sample - loss: 0.6557 - val_loss: 0.6355\n",
      "Epoch 7/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.6361 - val_loss: 0.6153\n",
      "Epoch 8/600\n",
      "426/426 [==============================] - 0s 144us/sample - loss: 0.6155 - val_loss: 0.5897\n",
      "Epoch 9/600\n",
      "426/426 [==============================] - 0s 117us/sample - loss: 0.5842 - val_loss: 0.5570\n",
      "Epoch 10/600\n",
      "426/426 [==============================] - 0s 132us/sample - loss: 0.5812 - val_loss: 0.5222\n",
      "Epoch 11/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.5569 - val_loss: 0.4890\n",
      "Epoch 12/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.5426 - val_loss: 0.4631\n",
      "Epoch 13/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.5167 - val_loss: 0.4338\n",
      "Epoch 14/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.4646 - val_loss: 0.4054\n",
      "Epoch 15/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.4660 - val_loss: 0.3760\n",
      "Epoch 16/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.4293 - val_loss: 0.3483\n",
      "Epoch 17/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.4245 - val_loss: 0.3266\n",
      "Epoch 18/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.4102 - val_loss: 0.3082\n",
      "Epoch 19/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.3634 - val_loss: 0.2877\n",
      "Epoch 20/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.3940 - val_loss: 0.2685\n",
      "Epoch 21/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.3732 - val_loss: 0.2575\n",
      "Epoch 22/600\n",
      "426/426 [==============================] - 0s 120us/sample - loss: 0.3420 - val_loss: 0.2409\n",
      "Epoch 23/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.2960 - val_loss: 0.2246\n",
      "Epoch 24/600\n",
      "426/426 [==============================] - 0s 134us/sample - loss: 0.3284 - val_loss: 0.2120\n",
      "Epoch 25/600\n",
      "426/426 [==============================] - 0s 183us/sample - loss: 0.3013 - val_loss: 0.2005\n",
      "Epoch 26/600\n",
      "426/426 [==============================] - 0s 172us/sample - loss: 0.2557 - val_loss: 0.1871\n",
      "Epoch 27/600\n",
      "426/426 [==============================] - 0s 159us/sample - loss: 0.2738 - val_loss: 0.1760\n",
      "Epoch 28/600\n",
      "426/426 [==============================] - 0s 249us/sample - loss: 0.2730 - val_loss: 0.1710\n",
      "Epoch 29/600\n",
      "426/426 [==============================] - 0s 269us/sample - loss: 0.2783 - val_loss: 0.1671\n",
      "Epoch 30/600\n",
      "426/426 [==============================] - 0s 293us/sample - loss: 0.2610 - val_loss: 0.1587\n",
      "Epoch 31/600\n",
      "426/426 [==============================] - 0s 284us/sample - loss: 0.2694 - val_loss: 0.1606\n",
      "Epoch 32/600\n",
      "426/426 [==============================] - 0s 299us/sample - loss: 0.2656 - val_loss: 0.1567\n",
      "Epoch 33/600\n",
      "426/426 [==============================] - 0s 306us/sample - loss: 0.2495 - val_loss: 0.1523\n",
      "Epoch 34/600\n",
      "426/426 [==============================] - 0s 292us/sample - loss: 0.2298 - val_loss: 0.1491\n",
      "Epoch 35/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.2647 - val_loss: 0.1353\n",
      "Epoch 36/600\n",
      "426/426 [==============================] - 0s 115us/sample - loss: 0.2240 - val_loss: 0.1316\n",
      "Epoch 37/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.2081 - val_loss: 0.1272\n",
      "Epoch 38/600\n",
      "426/426 [==============================] - 0s 121us/sample - loss: 0.2151 - val_loss: 0.1262\n",
      "Epoch 39/600\n",
      "426/426 [==============================] - 0s 148us/sample - loss: 0.2192 - val_loss: 0.1249\n",
      "Epoch 40/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.2018 - val_loss: 0.1265\n",
      "Epoch 41/600\n",
      "426/426 [==============================] - 0s 187us/sample - loss: 0.2055 - val_loss: 0.1173\n",
      "Epoch 42/600\n",
      "426/426 [==============================] - 0s 151us/sample - loss: 0.2083 - val_loss: 0.1331\n",
      "Epoch 43/600\n",
      "426/426 [==============================] - 0s 161us/sample - loss: 0.1873 - val_loss: 0.1132\n",
      "Epoch 44/600\n",
      "426/426 [==============================] - 0s 152us/sample - loss: 0.2091 - val_loss: 0.1112\n",
      "Epoch 45/600\n",
      "426/426 [==============================] - 0s 158us/sample - loss: 0.1648 - val_loss: 0.1136\n",
      "Epoch 46/600\n",
      "426/426 [==============================] - 0s 164us/sample - loss: 0.1865 - val_loss: 0.1095\n",
      "Epoch 47/600\n",
      "426/426 [==============================] - 0s 154us/sample - loss: 0.1873 - val_loss: 0.1060\n",
      "Epoch 48/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.2156 - val_loss: 0.1079\n",
      "Epoch 49/600\n",
      "426/426 [==============================] - 0s 164us/sample - loss: 0.1727 - val_loss: 0.1072\n",
      "Epoch 50/600\n",
      "426/426 [==============================] - 0s 142us/sample - loss: 0.1621 - val_loss: 0.1013\n",
      "Epoch 51/600\n",
      "426/426 [==============================] - 0s 157us/sample - loss: 0.1836 - val_loss: 0.1131\n",
      "Epoch 52/600\n",
      "426/426 [==============================] - 0s 141us/sample - loss: 0.1598 - val_loss: 0.1073\n",
      "Epoch 53/600\n",
      "426/426 [==============================] - 0s 152us/sample - loss: 0.1758 - val_loss: 0.0987\n",
      "Epoch 54/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.1425 - val_loss: 0.1006\n",
      "Epoch 55/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.1559 - val_loss: 0.1117\n",
      "Epoch 56/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.1606 - val_loss: 0.0973\n",
      "Epoch 57/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.1425 - val_loss: 0.1001\n",
      "Epoch 58/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.1439 - val_loss: 0.0939\n",
      "Epoch 59/600\n",
      "426/426 [==============================] - 0s 109us/sample - loss: 0.1583 - val_loss: 0.0983\n",
      "Epoch 60/600\n",
      "426/426 [==============================] - 0s 118us/sample - loss: 0.1372 - val_loss: 0.0916\n",
      "Epoch 61/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.1693 - val_loss: 0.0985\n",
      "Epoch 62/600\n",
      "426/426 [==============================] - 0s 130us/sample - loss: 0.1413 - val_loss: 0.1014\n",
      "Epoch 63/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.1545 - val_loss: 0.0944\n",
      "Epoch 64/600\n",
      "426/426 [==============================] - 0s 132us/sample - loss: 0.1528 - val_loss: 0.0936\n",
      "Epoch 65/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.1155 - val_loss: 0.0911\n",
      "Epoch 66/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.1391 - val_loss: 0.0874\n",
      "Epoch 67/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.1253 - val_loss: 0.0949\n",
      "Epoch 68/600\n",
      "426/426 [==============================] - 0s 128us/sample - loss: 0.1261 - val_loss: 0.0980\n",
      "Epoch 69/600\n",
      "426/426 [==============================] - 0s 122us/sample - loss: 0.1172 - val_loss: 0.0878\n",
      "Epoch 70/600\n",
      "426/426 [==============================] - 0s 126us/sample - loss: 0.1265 - val_loss: 0.0870\n",
      "Epoch 71/600\n",
      "426/426 [==============================] - 0s 131us/sample - loss: 0.1394 - val_loss: 0.0951\n",
      "Epoch 72/600\n",
      "426/426 [==============================] - 0s 183us/sample - loss: 0.1152 - val_loss: 0.0879\n",
      "Epoch 73/600\n",
      "426/426 [==============================] - 0s 176us/sample - loss: 0.1230 - val_loss: 0.0858\n",
      "Epoch 74/600\n",
      "426/426 [==============================] - 0s 240us/sample - loss: 0.1378 - val_loss: 0.0863\n",
      "Epoch 75/600\n",
      "426/426 [==============================] - 0s 259us/sample - loss: 0.1271 - val_loss: 0.0887\n",
      "Epoch 76/600\n",
      "426/426 [==============================] - 0s 263us/sample - loss: 0.1238 - val_loss: 0.0866\n",
      "Epoch 77/600\n",
      "426/426 [==============================] - 0s 265us/sample - loss: 0.1330 - val_loss: 0.0825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/600\n",
      "426/426 [==============================] - 0s 105us/sample - loss: 0.0989 - val_loss: 0.0835\n",
      "Epoch 79/600\n",
      "426/426 [==============================] - 0s 123us/sample - loss: 0.1251 - val_loss: 0.0873\n",
      "Epoch 80/600\n",
      "426/426 [==============================] - 0s 144us/sample - loss: 0.1331 - val_loss: 0.0829\n",
      "Epoch 81/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.1081 - val_loss: 0.0793\n",
      "Epoch 82/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.1386 - val_loss: 0.0809\n",
      "Epoch 83/600\n",
      "426/426 [==============================] - 0s 136us/sample - loss: 0.1028 - val_loss: 0.0843\n",
      "Epoch 84/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.1255 - val_loss: 0.0805\n",
      "Epoch 85/600\n",
      "426/426 [==============================] - 0s 133us/sample - loss: 0.1171 - val_loss: 0.0842\n",
      "Epoch 86/600\n",
      "426/426 [==============================] - 0s 151us/sample - loss: 0.1160 - val_loss: 0.0871\n",
      "Epoch 87/600\n",
      "426/426 [==============================] - 0s 129us/sample - loss: 0.0992 - val_loss: 0.0772\n",
      "Epoch 88/600\n",
      "426/426 [==============================] - 0s 155us/sample - loss: 0.1135 - val_loss: 0.0935\n",
      "Epoch 89/600\n",
      "426/426 [==============================] - 0s 150us/sample - loss: 0.1229 - val_loss: 0.0822\n",
      "Epoch 90/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.1215 - val_loss: 0.0902\n",
      "Epoch 91/600\n",
      "426/426 [==============================] - 0s 132us/sample - loss: 0.0987 - val_loss: 0.0798\n",
      "Epoch 92/600\n",
      "426/426 [==============================] - 0s 151us/sample - loss: 0.1169 - val_loss: 0.0795\n",
      "Epoch 93/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.1040 - val_loss: 0.0798\n",
      "Epoch 94/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.1045 - val_loss: 0.0890\n",
      "Epoch 95/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.1155 - val_loss: 0.0793\n",
      "Epoch 96/600\n",
      "426/426 [==============================] - 0s 152us/sample - loss: 0.0917 - val_loss: 0.0796\n",
      "Epoch 97/600\n",
      "426/426 [==============================] - 0s 138us/sample - loss: 0.1182 - val_loss: 0.0808\n",
      "Epoch 98/600\n",
      "426/426 [==============================] - 0s 134us/sample - loss: 0.1048 - val_loss: 0.0767\n",
      "Epoch 99/600\n",
      "426/426 [==============================] - 0s 137us/sample - loss: 0.0958 - val_loss: 0.0841\n",
      "Epoch 100/600\n",
      "426/426 [==============================] - 0s 148us/sample - loss: 0.0973 - val_loss: 0.0826\n",
      "Epoch 101/600\n",
      "426/426 [==============================] - 0s 145us/sample - loss: 0.0875 - val_loss: 0.0789\n",
      "Epoch 102/600\n",
      "426/426 [==============================] - 0s 142us/sample - loss: 0.0840 - val_loss: 0.0786\n",
      "Epoch 103/600\n",
      "426/426 [==============================] - 0s 134us/sample - loss: 0.1047 - val_loss: 0.0787\n",
      "Epoch 104/600\n",
      "426/426 [==============================] - 0s 158us/sample - loss: 0.0967 - val_loss: 0.0916\n",
      "Epoch 105/600\n",
      "426/426 [==============================] - 0s 139us/sample - loss: 0.0912 - val_loss: 0.0864\n",
      "Epoch 106/600\n",
      "426/426 [==============================] - 0s 143us/sample - loss: 0.1228 - val_loss: 0.0885\n",
      "Epoch 107/600\n",
      "426/426 [==============================] - 0s 135us/sample - loss: 0.1087 - val_loss: 0.0794\n",
      "Epoch 108/600\n",
      "426/426 [==============================] - 0s 141us/sample - loss: 0.0945 - val_loss: 0.0914\n",
      "Epoch 109/600\n",
      "426/426 [==============================] - 0s 160us/sample - loss: 0.1032 - val_loss: 0.0805\n",
      "Epoch 110/600\n",
      "426/426 [==============================] - 0s 142us/sample - loss: 0.0963 - val_loss: 0.0836\n",
      "Epoch 111/600\n",
      "426/426 [==============================] - 0s 153us/sample - loss: 0.1010 - val_loss: 0.0825\n",
      "Epoch 112/600\n",
      "426/426 [==============================] - 0s 146us/sample - loss: 0.0909 - val_loss: 0.0841\n",
      "Epoch 113/600\n",
      "426/426 [==============================] - 0s 127us/sample - loss: 0.0918 - val_loss: 0.0827\n",
      "Epoch 114/600\n",
      "426/426 [==============================] - ETA: 0s - loss: 0.074 - 0s 144us/sample - loss: 0.0807 - val_loss: 0.0851\n",
      "Epoch 115/600\n",
      "426/426 [==============================] - 0s 146us/sample - loss: 0.0917 - val_loss: 0.0825\n",
      "Epoch 116/600\n",
      "426/426 [==============================] - 0s 160us/sample - loss: 0.0947 - val_loss: 0.0795\n",
      "Epoch 117/600\n",
      "426/426 [==============================] - 0s 148us/sample - loss: 0.0850 - val_loss: 0.0920\n",
      "Epoch 118/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0760 - val_loss: 0.0768\n",
      "Epoch 119/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0999 - val_loss: 0.0786\n",
      "Epoch 120/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.1099 - val_loss: 0.0849\n",
      "Epoch 121/600\n",
      "426/426 [==============================] - 0s 147us/sample - loss: 0.0895 - val_loss: 0.0815\n",
      "Epoch 122/600\n",
      "426/426 [==============================] - 0s 153us/sample - loss: 0.0922 - val_loss: 0.0958\n",
      "Epoch 123/600\n",
      "426/426 [==============================] - 0s 140us/sample - loss: 0.0901 - val_loss: 0.0808\n",
      "Epoch 00123: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x158a91ab208>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=600,validation_data=(X_test,y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x158a2470208>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distorted shape of graph just come due to the fact that we don't have a perfect cost function on which we are working on\n",
    "# due to dropping out randomly the neurons from each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        55\n",
      "           1       0.99      0.99      0.99        88\n",
      "\n",
      "    accuracy                           0.99       143\n",
      "   macro avg       0.99      0.99      0.99       143\n",
      "weighted avg       0.99      0.99      0.99       143\n",
      "\n",
      "[[54  1]\n",
      " [ 1 87]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9409090909090909"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9501574598063126"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_train,model.predict_classes(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
